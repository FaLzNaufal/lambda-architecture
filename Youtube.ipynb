{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeTime(time):\n",
    "    res = ''\n",
    "    for i in range(len(time)):\n",
    "        if i == 6 or i == 7:\n",
    "            res += '0'\n",
    "        elif i == 4:\n",
    "            if int(time[i]) < 5:\n",
    "                res += '0'\n",
    "            else:\n",
    "                res += '5'\n",
    "        else:\n",
    "            res += time[i] \n",
    "    return res\n",
    "\n",
    "def parseTime(type, time):\n",
    "    if type == \"twitter\":\n",
    "        ts = t.strftime('%Y-%m-%d %H:%M:%S', t.strptime(time,'%a %b %d %H:%M:%S +0000 %Y'))\n",
    "        return ts[:10]\n",
    "    elif type == \"instagram\" or type == \"other\":\n",
    "        time = str(datetime.datetime.fromtimestamp(int(time)).date())\n",
    "        return time[:10]\n",
    "    else:\n",
    "        return time[:10] + ' ' + normalizeTime(time[11:19])\n",
    "    \n",
    "def process_rdd(rdd):\n",
    "    # Collect the tuples inside the RDD as a list\n",
    "    data = rdd.collect()\n",
    "    # Process the data\n",
    "    for row in data:\n",
    "        insertToSQL(row)\n",
    "        \n",
    "\n",
    "def insertToSQL(data):\n",
    "    \n",
    "    conn = psycopg2.connect(database=\"bigdatatest\",\n",
    "     host=\"localhost\",\n",
    "     user=\"geraldakbar\",\n",
    "     password='bigdata'\n",
    "     )\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    social_media = data[0]\n",
    "    timestamp = data[1]\n",
    "    count = data[2]\n",
    "    uniquecount = data[3]\n",
    "\n",
    "    query = f\"\"\"INSERT INTO social_media_data (social_media, timestamp, count, uniquecount)\n",
    "                    VALUES ('{social_media}', '{timestamp}', {count}, {uniquecount})\n",
    "                    ON CONFLICT (social_media, timestamp) DO UPDATE\n",
    "                    SET count = CASE WHEN social_media_data.count IS NULL THEN 1 ELSE social_media_data.count + {count} END,\n",
    "                    uniquecount = CASE WHEN social_media_data.uniquecount IS NULL THEN 1 ELSE social_media_data.uniquecount + {uniquecount} END,\n",
    "                    updated_at = NOW();\"\"\"\n",
    "\n",
    "\n",
    "    cur.execute(query)\n",
    "    print(\"Inserted Data:\",data)\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/18 06:17:55 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798675000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16506): File does not exist. Holder DFSClient_NONMAPREDUCE_-435975537_16 does not have any open files.\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/18 06:17:55 WARN hdfs.DFSClient: DataStreamer Exception\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16508): File does not exist. Holder DFSClient_NONMAPREDUCE_-435975537_16 does not have any open files.\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3185)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3032)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:722)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448)\n",
      "23/04/18 06:17:55 WARN streaming.CheckpointWriter: Error in attempt 2 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798675000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16508): File does not exist. Holder DFSClient_NONMAPREDUCE_-435975537_16 does not have any open files.\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3185)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3032)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:722)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                  (0 + 4) / 5][Stage 2:>                  (0 + 0) / 5]23/04/18 06:17:56 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798676000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16511): File does not exist. Holder DFSClient_NONMAPREDUCE_-435975537_16 does not have any open files.\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "[Stage 3:>                                                          (0 + 4) / 4]23/04/18 06:17:57 WARN hdfs.DFSClient: DataStreamer Exception\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16515): File does not exist. Holder DFSClient_NONMAPREDUCE_-435975537_16 does not have any open files.\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3185)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3032)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:722)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448)\n",
      "23/04/18 06:17:57 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798677000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16515): File does not exist. Holder DFSClient_NONMAPREDUCE_-435975537_16 does not have any open files.\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3185)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3032)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:722)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r",
      "23/04/18 06:17:58 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798678000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16519): File does not exist. Holder DFSClient_NONMAPREDUCE_-435975537_16 does not have any open files.\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/18 06:17:58 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798678000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16522): File does not exist. Holder DFSClient_NONMAPREDUCE_-435975537_16 does not have any open files.\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted Data: ('youtube', '2023-04-04 16:45:00', 1, 1)\n",
      "Inserted Data: ('youtube', '2023-04-04 17:05:00', 2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/18 06:18:00 WARN hdfs.DFSClient: DataStreamer Exception\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16530): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3185)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3032)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:722)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
      "\tat sun.reflect.GeneratedMethodAccessor49.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448)\n",
      "23/04/18 06:18:00 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798680000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16530): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3185)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3032)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:722)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
      "\tat sun.reflect.GeneratedMethodAccessor49.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448)\n",
      "23/04/18 06:18:00 WARN streaming.CheckpointWriter: Error in attempt 2 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798680000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16532): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted Data: ('youtube', '2023-04-04 17:00:00', 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/18 06:18:01 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798680000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16535): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/18 06:18:02 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798682000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16540): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/18 06:18:02 WARN streaming.CheckpointWriter: Error in attempt 2 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798682000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16542): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/18 06:18:03 WARN streaming.CheckpointWriter: Error in attempt 3 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798682000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16544): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/18 06:18:03 WARN streaming.CheckpointWriter: Could not write checkpoint for time 1681798682000 ms to file 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798682000'\n",
      "23/04/18 06:18:03 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798683000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16546): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/18 06:18:05 WARN hdfs.DFSClient: DataStreamer Exception\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16554): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3185)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3032)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:722)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
      "\tat sun.reflect.GeneratedMethodAccessor49.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448)\n",
      "23/04/18 06:18:05 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798685000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16554): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3185)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3032)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:722)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
      "\tat sun.reflect.GeneratedMethodAccessor49.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448)\n",
      "23/04/18 06:18:05 WARN streaming.CheckpointWriter: Error in attempt 2 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798685000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16556): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted Data: ('youtube', '2023-04-04 17:05:00', 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/18 06:18:06 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798686000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16561): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/18 06:18:06 WARN hdfs.DFSClient: DataStreamer Exception\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16563): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3185)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3032)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:722)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
      "\tat sun.reflect.GeneratedMethodAccessor49.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448)\n",
      "23/04/18 06:18:06 WARN streaming.CheckpointWriter: Error in attempt 2 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798686000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16563): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3185)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3032)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:722)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
      "\tat sun.reflect.GeneratedMethodAccessor49.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/18 06:18:08 WARN hdfs.DFSClient: DataStreamer Exception\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16569): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3185)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3032)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:722)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
      "\tat sun.reflect.GeneratedMethodAccessor49.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448)\n",
      "23/04/18 06:18:08 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798688000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16569): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3185)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3032)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:722)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
      "\tat sun.reflect.GeneratedMethodAccessor49.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted Data: ('youtube', '2023-04-04 17:00:00', 1, 1)\n",
      "Inserted Data: ('youtube', '2023-04-04 17:05:00', 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/18 06:18:10 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798690000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16578): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/18 06:18:10 WARN streaming.CheckpointWriter: Error in attempt 2 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798690000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16580): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/18 06:18:11 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798691000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16584): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/18 06:18:11 WARN hdfs.DFSClient: DataStreamer Exception\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16586): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3185)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3032)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:722)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
      "\tat sun.reflect.GeneratedMethodAccessor49.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448)\n",
      "23/04/18 06:18:11 WARN streaming.CheckpointWriter: Error in attempt 2 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798691000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16586): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:3185)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3032)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:722)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:492)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:418)\n",
      "\tat sun.reflect.GeneratedMethodAccessor49.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.addBlock(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1455)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1251)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448)\n",
      "23/04/18 06:18:11 WARN streaming.CheckpointWriter: Error in attempt 3 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798691000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16588): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/18 06:18:11 WARN streaming.CheckpointWriter: Could not write checkpoint for time 1681798691000 ms to file 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798691000'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/18 06:18:12 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798692000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16590): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/18 06:18:12 WARN streaming.CheckpointWriter: Error in attempt 2 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798692000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16592): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/18 06:18:13 WARN streaming.CheckpointWriter: Error in attempt 3 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798692000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16594): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/18 06:18:13 WARN streaming.CheckpointWriter: Could not write checkpoint for time 1681798692000 ms to file 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798692000'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/18 06:18:13 WARN streaming.CheckpointWriter: Error in attempt 1 of writing checkpoint to 'hdfs://localhost:9000/user/geraldakbar/checkpoint/checkpoint-1681798693000'\n",
      "org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/geraldakbar/checkpoint/temp (inode 16597): File does not exist. [Lease.  Holder: DFSClient_NONMAPREDUCE_-435975537_16, pendingcreates: 1]\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3386)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:3478)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3445)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:784)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:536)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1475)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n",
      "\tat com.sun.proxy.$Proxy20.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:462)\n",
      "\tat sun.reflect.GeneratedMethodAccessor61.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n",
      "\tat com.sun.proxy.$Proxy21.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:2291)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:2267)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:2232)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler$$anonfun$run$2.apply$mcV$sp(Checkpoint.scala:249)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1369)\n",
      "\tat org.apache.spark.streaming.CheckpointWriter$CheckpointWriteHandler.run(Checkpoint.scala:248)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6343/22008958.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforeachRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_rdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/streaming/context.py\u001b[0m in \u001b[0;36mawaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \"\"\"\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTerminationOrTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "ssc = StreamingContext(sc,1) #stream each one second\n",
    "ssc.checkpoint(\"./checkpoint\")\n",
    "lines = KafkaUtils.createDirectStream(ssc, ['youtube'],\n",
    "                                      {\"metadata.broker.list\": \"localhost:9092\"})\n",
    "\n",
    "def getYT(lines):\n",
    "    # map the lines to a key-value pair\n",
    "    def map(line):\n",
    "        snippet = line['snippet']\n",
    "        date = snippet['publishedAt'][0:10] + ' ' + normalizeTime(snippet['publishedAt'][11:19])\n",
    "        return ((\"youtube\", date), 1)\n",
    "    \n",
    "    def userMap(line):\n",
    "        snippet = line['snippet']\n",
    "        user = None\n",
    "        # check if comment is a reply\n",
    "        if('channelTitle' in snippet):\n",
    "            user = snippet['channelId']\n",
    "        else:\n",
    "            user = snippet['authorChannelId']['value']\n",
    "        date = snippet['publishedAt'][0:10] + ' ' + normalizeTime(snippet['publishedAt'][11:19])\n",
    "        return ((\"youtube\", date, user), 1)\n",
    "\n",
    "    lines = lines.window(5, 5)\n",
    "    lines = lines.map(lambda x: json.loads(x[1]))\n",
    "    ytPost = lines.map(map)\n",
    "    ytPost = ytPost.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "    user = lines.map(userMap)\n",
    "    user = user.transform(lambda rdd: rdd.distinct())\n",
    "    user = user.map(lambda x: ((x[0][0], x[0][1]), x[1]))\n",
    "    user = user.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "    ytPost = ytPost.join(user).map(lambda x: (x[0], x[1][0], x[1][1]))\n",
    "    ytPost = ytPost.map(lambda x: (x[0][0], x[0][1], x[1], x[2]))\n",
    "    # ytPost = masukin ke postgre\n",
    "    return ytPost\n",
    "\n",
    "result = getYT(lines)\n",
    "# Print\n",
    "result.foreachRDD(process_rdd)\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
